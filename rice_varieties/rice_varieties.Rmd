---
title: "Rice Varieties Classification"
author: "Group D"
date: "2024-04-22"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

-   **Davide Albiero** davide.albiero@studenti.unipd.it
-   **Nazanin Ghorbani** nazanin.ghorbani@studenti.unipd.it
-   **Raman Yudzeshka** raman.yudzeshka@studenti.unipd.it
-   **Niccol√≤ Zenaro** niccolo.zenaro@studenti.unipd.it
-   **Luca Marchiori** luca.marchiori.3@studenti.unipd.it
-   **Mohammad Khosravi** mohammad.khosravi.1@studenti.unipd.it


```{r include=FALSE}
# Clear workspace, install library & import data
library("corrplot")
library("caret")
library("class")
library("Metrics")
library("MASS")
library("ggplot2")
library("gridExtra")
library("klaR")
set.seed(1234)
```

## Importing Dataset (Task #1)
```{r}
rm(list = ls())
data <- read.csv("./dataset/rice_train.csv")
data$Class <- as.factor(data$Class)
summary(data)
```
## Data exploration (Task #2)

### Boxplots
```{r}
#boxplot(data$Area ~ data$Class, xlab="Class", ylab = "Area")
#boxplot(data$Perimeter ~ data$Class, xlab="Class", ylab = "Perimeter")
#boxplot(data$Major_Axis_Length ~ data$Class, xlab="Class", ylab = "MajorAxisLength")
#boxplot(data$Minor_Axis_Length ~ data$Class, xlab="Class", ylab = "MinorAxisLength")
#boxplot(data$Eccentricity ~ data$Class, xlab="Class", ylab = "Eccentricity")
boxplot(data$Convex_Area ~ data$Class, xlab="Class", ylab = "ConvexArea")
#boxplot(data$Extent ~ data$Class, xlab="Class", ylab = "Extent")


#plot(data[,1:7])

#cor(data[,1:7])
corrplot(cor(data[,1:7]), method = "number")
```

### Scatterplots
```{r}
plot(data[,], col=ifelse(data$Class == 1, "darkred", "lightblue"))
plot(data$Convex_Area, data$Area, type='p', col=ifelse(data$Class == 1, "darkred", "lightblue"), xlab = "ConvexArea", ylab = "Area")
```

```{r}
plot(data$Area, type='p', col="red", ylab = "Area vs Convex Area")
points(data$Convex_Area, type = "p", col="black")
```

```{r}
# Remove Area from data set
# Convex_Area is highly correlated with Area
data$Area <- NULL
trainIndex <- createDataPartition(data$Class,
                                  times = 1,
                                  p = .8, 
                                  list = FALSE)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]
```


## Performing LDA (Task #4)
```{r}
ldaModel <- lda(formula = Class ~ ., data = train)
ldaModel
```
With two classes (0/1), LDA produces only one discriminant function, which is sufficient to separate between the two classes in a one-dimensional space. Hence, the proportion of trace (percentage separations archived by LD1) is 100%
```{r}
predLda.train <- predict(ldaModel, newdata = train)
predLda.test <- predict(ldaModel, newdata = test)

# Determine how well the model fits
confusionMatrix(predLda.train$class, train$Class)
confusionMatrix(predLda.test$class, test$Class)
#https://forum.edgeimpulse.com/t/test-data-set-higher-accuracy-than-training-data-set/8200
```
A Stacked Histogram can be used to see the class separation. The separation between the two classes is clear but with some overlap.
```{r}
ldahist(data = predLda.train$x, g=train$Class)
partimat(Class ~ ., data = test, method = "lda", plot.matrix = TRUE, col.correct='green', col.wrong='red')
```

```{r}
# Try with cross validation leave one out
ldaModelCV <- lda(formula = Class ~ ., data = data, CV = TRUE)

confusionMatrix(ldaModelCV$class, data$Class)
```
Based on the Accuracy, the model that we chose is the one without CV.

## Performing QDA (Task #5)
```{r}
qdaModel <- qda(formula = Class ~ ., data = train)
qdaModel
```

```{r}
predQda.train <- predict(qdaModel, newdata = train)
predQda.test <- predict(qdaModel, newdata = test)

# Determine how well the model fits
confusionMatrix(predQda.train$class, train$Class)
confusionMatrix(predQda.test$class, test$Class)
```

```{r}
partimat(Class ~ ., data = test, method = "qda", plot.matrix = TRUE, col.correct='green', col.wrong='red')
```

```{r}
# Try with cross validation leave one out
qdaModelCV <- qda(formula = Class ~ ., data = data, CV = TRUE)

confusionMatrix(qdaModelCV$class, data$Class)
```

## Performing Logistic Regression (Task #6)

With the logistic regression model, the performances of the models have been evaluated one at a time by excluding one of the lesser important features. First, area; minor axis; extent; then minor axis; and finally, just extent in the models. It can be seen from the results that simply using all features for logistic regression had a higher accuracy than when some of the features were dropped. So, the final model have the accuracy of 0.9537 using all the features.

```{r}
# Fitting the Logestic Regression model
glm.fits = glm(Class~ ., data = train, family = binomial)
# Making prediction on the new data
predictions <- predict(glm.fits, newdata = test, type = "response") 
# Convert probabilities to predicted classes (0 or 1)
predicted_classes <- ifelse(predictions > 0.5, 2, 1)
confusionMatrix(as.factor(predicted_classes), test$Class)
```

## Performing KNN (Task #7)

Centering involves subtracting the mean of each variable, while scaling involves dividing by the standard deviation, ensuring that all variables have a mean of zero and a standard deviation of one.
The K is tuned using a grid search ranging from 1 to 81 with a step size of 5. After the cross-validation, the best K (=41) is selected based on the accuracy.
```{r}
#preproc

preProcValues <- preProcess(train, method = c("center", "scale"))
trainKNN <- predict(preProcValues, train)
testKNN <- predict(preProcValues, test)

knnModel <- train(
  Class ~ ., 
	data = trainKNN,
  method = "knn", 
  trControl = trainControl(method = "cv"), 
  tuneGrid = data.frame(k = seq(1,81, by=5)))

best_model<- knn3(
  Class ~ .,
  data = trainKNN,
  k = knnModel$bestTune$k)
print(knnModel$bestTune$k)

predictions <- predict(best_model, testKNN, type = "class")
# Calculate confusion matrix
confusionMatrix(predictions, testKNN$Class)
```