---
title: "Toxicity TApp Group D"
output: html_notebook
---


```{r}
# Load libraries
library(caret)
library(ggplot2)
library(corrplot)
library(mgcv)
library(tidyr)
library(dplyr)
#Clear the workspace
rm(list=ls())
```

## Data import
```{r}
# Load the training data
train <- read.csv("toxicity_train.csv", stringsAsFactors=F)
# Load the test data
test <- read.csv("toxicity_validation.csv", stringsAsFactors=F)
```
## Helpers
### Minimal Squared Error
MSE (Mean Squared Error) is a common metric for evaluating the performance of regression models, by comparing the observed values `y` with the predicted values `yhat` generated by the provided `model`.
```{r}
MSE <- function(y, model){
  yhat = predict(model) # Estimated y computed on the basis of the features
  mean((y-yhat)^2)
}

RMSE <- function(y, model){
  sqrt(MSE(y,model))
}
```

### Task 3

For this task, we train the model multiple times by increasing at each train the polynomial degree (from 1 to 5). The RMSE of each model is calculated after the cross-validation. The cross validation is used to ensure that the calculated RMSE is a good quality and not biased measure.

The results show that the 2-degree polynomial is the one with the lowest RMSE. A plot that compares the RMSE and the degree of polynomial is shown. In the end we also plot the final model function on the data scatterplot.
```{r}
# Train a model by trying multiple polynomial degrees. Save the models and their cross-validated RMSEs in a list and choose the best model based on the RMSE.

set.seed(123)
degrees <- 1:7
models <- list()
rmses <- c()

fitControl <- trainControl(method = "cv", number = 20)

for (degree in degrees){
  # Build up the formula with the selected degree
  formula <- as.formula(paste("LC50 ~ poly(RDCHI, ", degree, ")", sep=""))
  
  # Train the model
  fit <- caret::train(formula, data=train, method="lm", trControl=fitControl, preProcess=c("center", "scale"))
  
  # Get the cross-validated RMSE
  fitRmse <- fit$results$RMSE
  # Save the model RMSE
  rmses <- c(rmses, fitRmse)
}

# Plot the flexibility of the model vs RMSE
ggplot(data.frame(degree=degrees, RMSE=rmses), aes(x=degree, y=RMSE)) + geom_point() + geom_line() + xlab("Degree of polynomial") + ylab("RMSE")

# Choose the best model
bestDegree <- degrees[which.min(rmses)]
bestDegree

# Train the best model again (just for the sake of plotting it)
bestFormula <- as.formula(paste("LC50 ~ poly(RDCHI, ", bestDegree, ")", sep=""))
bestFit <- lm(bestFormula, data=train, method="lm", trControl=fitControl)

# Plot the data and the best model
ggplot(train, aes(x=RDCHI, y=LC50)) + geom_point(size=0.5, color="#34495e") + geom_line(aes(y=predict(bestFit), color="#c0392b"), show.legend = FALSE)

```

## 4. 
```{r}
# let's use 30 DOF and compare step function and cubic spline
# then it'll be 30 knots for the step function and 26 for the cubic spline

knots <- quantile(train$RDCHI, probs = seq(0, 1, length.out = 26))

# Step function
train$RDCHI_step <- cut(train$RDCHI, breaks=30, labels=FALSE)

# Define the model formulas
step_model_formula <- LC50 ~ factor(RDCHI_step)
spline_model_formula <- as.formula(paste("LC50 ~ bs(RDCHI, knots = ", knots[-c(1, length(knots))], ", degree = 3)"))

spline_model_formula

# Define train control with 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)

str(train)
# Fit the models and calculate RMSE using cross-validation
model_step <- train(step_model_formula, data = train, method = "lm", trControl = ctrl)
model_spline <- train(spline_model_formula, data = train, method = "lm", trControl = ctrl)

summary(model_spline)


# Predicting
train$predicted_LC50_spline <- predict(model_spline, newdata=train)
train$predicted_LC50_step <- predict(model_step, newdata=train)

# Print RMSE for both models
cat("RMSE for Step Function Model (CV): ", model_step$results$RMSE, "\n")
cat("RMSE for Cubic Spline Model (CV): ", model_spline$results$RMSE, "\n")


# Plot the results
ggplot() +
  # Train data
  geom_point(data=train, aes(x = RDCHI, y = LC50), alpha = 0.5) +
  # Step function predictions
  stat_summary_bin(data=train, aes(x = RDCHI, y = predicted_LC50_step), 
                   bins = 30, geom = "step", color = "red", size = 1, alpha = 0.8) +
  # Cubic spline predictions
  geom_line(data=train, aes(x = RDCHI, y = predicted_LC50_spline), 
            color = "blue", size = 1, alpha = 0.8) +
  labs(title = "Step Function vs Cubic Spline Regression", 
       x = "RDCHI", 
       y = "LC50") +
  theme_minimal()


```

```{r}
#Task 6 - Mohammad
# Check the number of unique values in each predictor
sapply(train, function(x) length(unique(x)))

# Fit a GAM model using natural cubic splines with reduced knots for each predictor
gam_model <- gam(LC50 ~ 
                   s(TPSA, bs = "cs", k = 20) +   # Less than 193
                   s(SAacc, bs = "cs", k = 20) +  # Less than 182
                   s(H050, bs = "cs", k = 9) +    # Less than 10
                   s(MLOGP, bs = "cs", k = 20) +  # Less than 349 (k can be higher but 20 is reasonable)
                   s(RDCHI, bs = "cs", k = 20) +  # Less than 297 (k can be higher but 20 is reasonable)
                   s(GATS1p, bs = "cs", k = 20) + # Less than 349 (k can be higher but 20 is reasonable)
                   s(nN, bs = "cs", k = 9) +      # Less than 9
                   s(C040, bs = "cs", k = 6),     # Less than 6
                 data = train)

# Summarize the model
summary(gam_model)

# Extract partial effects of each predictor
partial_effects <- predict(gam_model, type = "terms", se.fit = TRUE)
partial_effects_df <- as.data.frame(partial_effects$fit)
colnames(partial_effects_df) <- gsub("\\.s\\(.*\\)", "", colnames(partial_effects_df))
partial_effects_df$LC50 <- train$LC50

# Convert the data to long format for ggplot
partial_effects_long <- partial_effects_df %>%
  pivot_longer(cols = -LC50, names_to = "Predictor", values_to = "Effect")

# Plot the effects of each predictor using ggplot2
ggplot(partial_effects_long, aes(x = Effect, y = LC50)) +
  geom_point() +
  facet_wrap(~ Predictor, scales = "free_x") +
  labs(title = "Partial Effects of Predictors on LC50 using natural cubic splines",
       x = "Partial Effect",
       y = "LC50") +
  theme_minimal()
```
